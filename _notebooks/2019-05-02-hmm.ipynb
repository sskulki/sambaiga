{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden markov model\n",
    "> \n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- image: images/svi.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM is a Markov model whose states are not directly observed; instead, each state is characterized by a probability distribution function modeling the observation corresponding to that state. HMM has been extensively used in temporal pattern recognition such as speech, handwriting, gesture recognition, robotics, biological sequences, and recently in energy disaggregation. This tutorial will introduce the basic concept of HMM.\n",
    "\n",
    "There are two variables in HMM: observed variables and hidden variables where the sequences of hidden variables form a Markov process, as shown in the figure below. \n",
    "\n",
    "![](my_icons/hmm.png)\n",
    "\n",
    "In the context of NILM, the hidden variables are used to model states(ON, OFF, standby etc.) of individual appliances, and the observed variables are used to model the electric usage. HMMs have been widely used in most of the recently proposed NILM approach because it represents well the individual appliance internal states which are not directly observed in the targeted energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical HMM is characterised by the following: \n",
    "\n",
    "- The finite set of hidden states $S $ (e.g ON, stand-by, OFF, etc.) of an appliance, $S = \\{s_1, s_2....,s_N\\} $. \n",
    "- The finite set of $M $ observable symbol $Y $ per states (power consumption) observed in each state, $Y = \\{y_1, y_2....,y_M\\} $. The observable symbol $Y $ can be discrete or a continuous set. \n",
    "- The transition matrix $\\mathbf{A}=\\{a_{ij},1\\leq i,j \\geq N\\} $ represents the probability of moving from state $s_{t-1}=i $ to $s_t =j $such that: $a_{ij} = P(s_{t} =j \\mid s_{t-1}=i) $, with $a_{ij} \\leq 0 $ and where $s_t $ denotes the state occupied by the system at time $t $. The matrix $\\mathbf{A} $ is $ N x N $.\n",
    "- The emission matrix $\\mathbf{B} =\\{b_j(k)\\} $ representing the probability of emission of symbol $k\\in  Y $ when system state is $s_t=j $ such that: $b_j(k) = p(y_t = k \\mid s_t=j)$ . The matrix $\\mathbf{B} $ is an $N x M $. The emission probability can be discrete or continous distribution. If the emission is descrete a multinomial distribution is used and multivariate Gaussian distribution is usually used for continous emission.\n",
    "- And the initial state probability distribution $\\mathbf{\\pi} = \\{\\pi_i \\ldots \\pi_N\\} $ indicating the probability of each state of the hidden variable at $t = 1 $ such that, $\\pi _i = P(q_1 = s_i), 1 \\leq i \\geq N $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete HMM specification requires;\n",
    "\n",
    "1. Finite set of hidden states $N $ and observation symbols $M$\n",
    "2. Length of observation seqences $T$ and\n",
    "3. Specification of three probability measures $ \\mathbf{A}, \\mathbf{B}$ and $\\mathbf{\\pi} $\n",
    "The set of all HMM model parameters is represented by $\\mathbf{\\lambda} =(\\pi, A, B)$. Since $S$ is not observed, the likelihood functions $Y$ is given by the joint distribution of $Y$ and $S$ over all possible states. \n",
    " $$\n",
    "P(Y \\mid \\lambda) = \\sum P(Y, S \\mid \\lambda)\n",
    " $$\n",
    "where \n",
    "$$\n",
    "P(Y,S \\mid \\lambda) = P(Y \\mid S,\\lambda)P(S \\mid \\lambda)\n",
    "$$\n",
    "Note that $y_t$ is independent and identically distributed given state sequence $S = \\{s_1, \\ldots s_N\\}$. Also each state at time $t$ depend on the state at its previous time $t-1$. Then\n",
    " $$\n",
    "P(Y \\mid S, \\lambda) = \\prod_{t=1}^T P(y_t \\mid s_t)\n",
    " $$\n",
    "Similarly\n",
    " $$\n",
    "P(S \\mid \\lambda) = \\pi _{s_1} \\prod _{t=2}^T a_{ij}\n",
    " $$\n",
    "The joint probability is therefore:\n",
    " $$\n",
    "P(Y \\mid \\lambda) = \\pi _{s_1}P(y_1 \\mid s_1) \\sum \\prod_{t=2}^T a_{ij} P(y_t \\mid s_t)\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three main problems in HMMs\n",
    "\n",
    "When applying HMM to a real-world problem, three essential issues must be solved. \n",
    "\n",
    "1. Evaluation Problem: Given HMM parameters $\\lambda$ and the observation sequence $Y = \\{Y_1, Y_2....,Y_M\\}$, find $P(Y \\mid \\lambda)$ the likelihood of the observation sequence $Y$ given the model $\\lambda$. This problem gives a score on how well a given model matches a given observation and thus allows you to choose the model that best matches the observation.\n",
    "2. Decoding Problem: Given HMM parameters $\\lambda$ and the observation sequence $Y = \\{Y_1, Y_2....,Y_M\\}$, find an optimal state sequence $S = \\{S_1, S_2....,S_N\\}$ which best explain the observation.This problem attempts to cover the hidden part of the model.\n",
    "3. Learning Problem: Given the observation sequence $Y = \\{Y_1, Y_2....,Y_M\\}$, find the model parameters $\\lambda$ that maximize $P(Y \\mid \\lambda)$.This problem attempts to optimize the model parameters to describe the model.\n",
    "\n",
    "The first and the second problem can be solved by the dynamic programming algorithms known as the Viterbi algorithm and the Forward-Backward algorithm, respectively. The last one can be solved by an iterative Expectation-Maximization (EM) algorithm, known as the Baum-Welch algorithm. We will discuss the first and the second problem in this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 1\n",
    "A straight forward way to solve this problem is to find $P(Y \\mid S, \\lambda)$ for fixed state sequences $S = \\{s_1,...s_T \\}$ and then sum up over all possible states. This is generally infeasible since it requires about $2TN^T$ multiplications. However, the problem can be efficiently solved by using the forward algorithm as follows:\n",
    " \n",
    "### The forward-backward Algorithm\n",
    "Let us define the **forward variable** \n",
    "$$\n",
    "\\alpha _t(i)=P(y_1,\\ldots y_t, s_t=i \\mid \\lambda)\n",
    "$$\n",
    "the probability of the partial observation sequences $y_1 \\ldots y_t$ up to time $t$ and the state $s_t =i$ at time $t$ given the model ${\\lambda}$. We also define an emission probability given HMM state $i$ at time $t$ as $b_i(y_t)$.\n",
    "\n",
    "#### Forward-Algorithm\n",
    "- **Initilization** \n",
    "\n",
    "    Let\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\alpha _1(i)&=P(y_1, s_1=i \\mid \\lambda) \\\\\n",
    "     & = P(y_1 \\mid s_1=i,\\lambda)P(s_1=i \\mid \\lambda)\\\\\n",
    "     &= \\pi _i b_i(y_1) \\text{ for } 1\\leq i \\geq N\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "- **Induction**\n",
    "\n",
    "    For $t=2,3...T$ and $1\\leq i \\geq N$, compute:\n",
    "   \n",
    "    \\begin{align}\n",
    "    \\alpha _{t}(i) & = P(y_1 \\ldots y_t, s_t=i \\mid \\lambda)\\\\\n",
    "     &= \\displaystyle \\sum_{j=1}^{N} P(y_1 \\ldots y_{t}, s_{t-1}=j,s_t=i \\mid \\lambda) \\\\\n",
    "     &= \\displaystyle \\sum_{j=1}^{N} P(y_t \\mid s_t=i, y_1,\\ldots y_{t-1}, s_{t-1}=j, \\lambda) \\\\\n",
    "     & \\times P(s_t=i \\mid y_1 \\ldots y_{t-1} \\ldots , s_{t-1}=j, \\lambda) \\\\\n",
    "     & \\times P(y_1 \\ldots y_{t-1}, s_{t-1}=j,\\lambda) \\\\\n",
    "     & = P(y_t \\mid s_t=i,\\lambda)\\displaystyle \\sum_{j=1}^{N} P(s_t=i \\mid s_{t-1}=j)\\cdot P(y_1, \\ldots y_{t-1}, s_{t-1}) \\\\\n",
    "    & = b_i(y_{t})\\displaystyle \\sum_{j=1}^{N} \\alpha _{t-1}(i)a_{ij} \n",
    "    \\end{align} \n",
    "\n",
    "- **Termination**\n",
    "    \n",
    "    From $\\alpha _t(i)=P(y_1,...y_t, s_t=i \\mid \\lambda)$, it cear that:\n",
    "    $$ \n",
    "    P(Y \\mid \\lambda) = \\displaystyle \\sum_{i=1}^{N} P(y_1,\\ldots y_T, s_T = i \\mid \\lambda) = \\displaystyle \\sum_{i=1}^{N}\\alpha _T(i) \n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Algorithm\n",
    "This is the same as the forward algorithm discussed in the previous sectionexcept that it start at the end and works backward toward the beginning. We first define the **backward variable** $\\beta_t(i)=P(y_{t+1},y_{t+2} \\ldots y_{T} \\mid s_t=i, {\\lambda})$: probability of the partial observed sequence from $$t+1 $$ to the end at $$T$$ given state $$i$$ at time $t$ and the model $\\lambda$. \n",
    "\n",
    "Then $\\beta_t(i)$ can be recursively computed as follows.\n",
    "- **Initialization**\n",
    "  Let $\\beta_{T}(i)= 1$, for $1 \\leq i\\geq N$\n",
    "- **Induction**\n",
    "  For $t =T-1, T-2,\\ldots1$ for $1 \\leq i\\geq N$ and by using the sum and product rules, we can rewrite $\\beta_t(j)$ as:\n",
    "\\begin{aligned}\n",
    "\\beta_t(i)&=P(y_{t+1},\\ldots y_{T} \\mid s_t=j, {\\lambda}) \\\\\n",
    " &= \\displaystyle \\sum_{i=1}^{N} P(y_{t+1} \\ldots y_T, s_{t+1}=i \\mid s_t=j, \\lambda) \\\\\n",
    " & = \\displaystyle \\sum_{i=1}^{N} P(y_{t+1} \\ldots y_T, s_{t+1}=i, s_t=j, \\lambda)\\cdot P(s_{t+1}=i \\mid s_t=j) \\\\\n",
    " &= \\displaystyle \\sum_{i=1}^{N} P(y_{t+2} \\ldots y_T, s_{t+1}=i, \\lambda)\\cdot P(y_{t+1} \\mid s_{t + 1}=i, \\lambda)\\cdot P(s_{t+1}=i \\mid s_t=j) \\\\\n",
    " & = \\displaystyle \\sum_{i=1}^{N} a_{ij}b_i(y_{t+1})\\beta _{t+1}(i)\n",
    "\\end{aligned}\n",
    "- **Termination**\n",
    "\\begin{aligned}\n",
    "\\beta_{0} & = P(Y \\mid \\lambda) \\\\\n",
    "& = \\displaystyle \\sum_{i=1}^{N} P(y_1,\\ldots y_T, s_1=i) \\\\\n",
    "&= \\displaystyle \\sum_{i=1}^{N} P(y_1,\\ldots y_T \\mid s_1=i)\\cdot P(s_1=i) \\\\\n",
    "& = \\displaystyle \\sum_{i=1}^{N} P(y_1 \\mid s_1=i)\\cdot P(y_2,\\ldots y_T \\mid s_1=i)\\cdot P(s_1=i) \\\\\n",
    "& = \\displaystyle \\sum_{i=1}^{N} \\pi _i b_i(y_1)\\beta _1(i)\n",
    "\\end{aligned}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "num_categories = 2\n",
    "num_words = 3\n",
    "num_supervised_data = 50\n",
    "num_data = 80\n",
    "\n",
    "pi = np.array([0.6, 0.4])  #initial probability \n",
    "transition_prior = torch.tensor([0.6, 0.4])\n",
    "emission_prior = torch.tensor([0.4, 0.2, 0.4])\n",
    "transition_prob = dist.Dirichlet(transition_prior).sample(torch.Size([num_categories]))\n",
    "emission_prob = dist.Dirichlet(emission_prior).sample(torch.Size([num_categories]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equilibrium(mc_matrix):\n",
    "    n = mc_matrix.size(0)\n",
    "    return (torch.eye(n) - mc_matrix.t() + 1).inverse().matmul(torch.ones(n))\n",
    "\n",
    "start_prob = equilibrium(transition_prob)\n",
    "\n",
    "# simulate data\n",
    "categories, words = [], []\n",
    "for t in range(num_data):\n",
    "    if t == 0 or t == num_supervised_data:\n",
    "        category = dist.Categorical(start_prob).sample()\n",
    "    else:\n",
    "        category = dist.Categorical(transition_prob[category]).sample()\n",
    "    word = dist.Categorical(emission_prob[category]).sample()\n",
    "    categories.append(category)\n",
    "    words.append(word)\n",
    "categories, words = torch.stack(categories), torch.stack(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ('Rainy', 'Sunny')\n",
    "observations = ('walk', 'shop', 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_seq=list(map(lambda y: observations[y], words.numpy()))\n",
    "state_seq=list(map(lambda y: states[y], categories.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_prob = pyro.sample(\"transition_prob\", dist.Dirichlet(transition_prior)).log().unsqueeze(0)\n",
    "transition_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob says: ,  ['walk', 'clean', 'shop', 'shop', 'clean', 'walk']\n"
     ]
    }
   ],
   "source": [
    "bob_says = np.array([0, 2, 1, 1, 2, 0])\n",
    "print(\"Bob says:\", \", \",list(map(lambda y: observations[y], bob_says)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference\n",
    "\n",
    "1. [[Cheng Zhang,(2017)]](https://arxiv.org/abs/1711.05597):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
