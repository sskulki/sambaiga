{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization and Distribution shapes in Pyro\n",
    "> This post present how to vectorize pyro codes\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [PPL, Pyro, Statistical Inference]\n",
    "- image: images/ppl-pyro-intro.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous post we introduced pyro and its building blocks such as schotastic function, primitive sample and param primitive statement, model and guide. We also defined pyro model and use it to generate data, learn from data and predict future observations.\n",
    "\n",
    "In this section, we will learn in details about inference in Pyro, how to use Pyro primitives and the effect handling library (pyro.poutine) to build custom tools for analysis.\n",
    "\n",
    "Consider a previous poison regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "pyro.set_rng_seed(101)\n",
    "torch.manual_seed(101)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(y):\n",
    "    slope = pyro.sample(\"slope\", dist.Normal(0, 0.1))\n",
    "    intercept = pyro.sample(\"intercept\", dist.Normal(0, 1))\n",
    "    for t in range(len(y)):\n",
    "        rate = torch.exp(intercept + slope * t)\n",
    "        y[t] = pyro.sample(\"count_{}\".format(t), dist.Poisson(rate),\n",
    "                                obs=y[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plate statement\n",
    "\n",
    "From the given  model above , **pyro.param** designate model parameters that we would like to optimize. Observations are denoted by the obs= keyword argument to pyro.sample. This specifies the likelihood function. Instead of log transforming the data, we use a LogNormal distribution. The observations are conditionally independent given the latent random variable slope and intercept. To explicitly mark this in Pyro, **plate** statement is used to construct conditionally independent sequences of variables.\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"name\", size, subsample_size, device) as ind:\n",
    "    # ...do conditionally independent stuff with ind...\n",
    "```\n",
    "However compared to ``range()`` each invocation of **plate** requires the user to provide a unique name. The **plate**  statement can be used either sequentially as a generator or in parallel as a context manager. Sequential plate is similar to ``range()``in that it generates a sequence of values. \n",
    "```python\n",
    " # This version declares sequential independence and subsamples data:\n",
    "    for i in plate('data', 100, subsample_size=10):\n",
    "         if z[i]:  # Control flow in this example prevents vectorization.\n",
    "                obs = sample('obs_{}'.format(i), dist.Normal(loc, scale), obs=data[i])\n",
    "```\n",
    "Vectorized plate is similar to ``torch.arange()`` in that it yields an array of indices by which other tensors can be indexed. However, unlike  ``torch.arange()`` **plate**  also informs inference algorithms that the variables being indexed are conditionally independent.\n",
    "```python\n",
    "     # This version declares vectorized independence:\n",
    "     with plate('data'):\n",
    "            obs = sample('obs', dist.Normal(loc, scale), obs=data)\n",
    "```\n",
    "Additionally, plate can take advantage of the conditional independence assumptions by subsampling the indices and informing inference algorithms to scale various computed values. This is typically used to subsample minibatches of data:\n",
    "```python\n",
    "with plate(\"data\", len(data), subsample_size=100) as ind:\n",
    "    batch = data[ind]\n",
    "    assert len(batch) == 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can additionally nest plates, e.g. if you have per-pixel independence:\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent\n",
    "```\n",
    "Finaly you can declare multiple plates and use them as reusable context managers. For example if you want to mix and match plates for e.g. noise that depends only on x, some noise that depends only on y, and some noise that depends on both\n",
    "\n",
    "```python\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    # within this context, batch dimension -2 is independent\n",
    "with y_axis:\n",
    "    # within this context, batch dimension -3 is independent\n",
    "with x_axis, y_axis:\n",
    "    # within this context, batch dimensions -3 and -2 are independent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(y):\n",
    "    slope = pyro.sample(\"slope\", dist.Normal(0, 0.1))\n",
    "    intercept = pyro.sample(\"intercept\", dist.Normal(0, 1))\n",
    "    with pyro.plate('N', len(y)) as t:                        \n",
    "        log_y_hat = slope * t.type(torch.float) + intercept\n",
    "        y=pyro.sample('y', dist.LogNormal(log_y_hat, 1.), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution shapes\n",
    "\n",
    "Unlike PyTorch Tensors which have  a single .shape attribute, pyro Distributions have two shape **batch_shape** and **event_shape**. These two combine to define the total shape of a sample. The batch_shape denote conditionally independent random variables, whereas .event_shape denote dependent random variables (ie one draw from a distribution). Because the dependent random variables define probability together, the .log_prob() method only produces a single number for each event of shape .event_shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "d = dist.Bernoulli(0.5)\n",
    "print(d.batch_shape)\n",
    "print(d.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = d.sample()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions can be batched by passing in batched parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "d = dist.Bernoulli(0.5*torch.ones(50))\n",
    "print(d.batch_shape)\n",
    "print(d.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = d.sample()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two examples above, we observe that univariate distributions have empty event shape (because each number is an independent event). Let also consider multivariate distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "md = dist.MultivariateNormal(torch.zeros(3), torch.eye(3))\n",
    "print(md.batch_shape)\n",
    "print(md.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = md.sample()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create batched multivariate distribution as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "md = dist.MultivariateNormal(torch.zeros(3), torch.eye(3)).expand([50])\n",
    "print(md.batch_shape)\n",
    "print(md.event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = md.sample()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Multivariate distributions have nonempty **.event_shape**, the shapes of .sample() and .log_prob(x) differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.log_prob(y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Distribution.sample()** method also takes a sample_shape parameter that indexes over independent identically   distributed (iid) random varables, such that:\n",
    "\n",
    "```python\n",
    "sample.shape == sample_shape + batch_shape + event_shape\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample =md.sample([10])\n",
    "y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping distributions\n",
    "\n",
    "You can treat a univariate distribution as multivariate by calling the ``.to_event(n)`` property where **n** is the number of batch dimensions (from the right) to declare as dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "d = dist.Bernoulli(0.5*torch.ones(50, 3)).to_event(1)\n",
    "print(d.batch_shape)\n",
    "print(d.event_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working with distributions in pyro it is essential to note that: \n",
    "1. Samples have shape batch_shape + event_shape, \n",
    "2. ``.log_prob(x)`` values have shape batch_shape. \n",
    "3. You’ll need to ensure that ``batch_shape`` is carefully controlled by either trimming it down with ``.to_event(n)`` or by declaring dimensions as independent via ``pyro.plate``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in Pyro we’ll declare some dimensions as dependent even though they are in fact independent. This allows us to easily swap in a MultivariateNormal distribution later, but aslo it simplifies the code as  we don’t need a plate. Consider the following two codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pyro.sample(\"x\", dist.Normal(0, 1).expand([10]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate(\"y_plate\", 10):\n",
    "    y = pyro.sample(\"y\", dist.Normal(0, 1))  # .expand([10]) is automatic\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two code examples, the second version with plate informs Pyro that it can make use of conditional independence information when estimating gradients, whereas in the first version Pyro must assume they are dependent (even though the normals are in fact conditionally independent)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}